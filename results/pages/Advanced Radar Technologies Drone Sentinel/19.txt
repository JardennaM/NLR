http://eprints.gla.ac.uk/164563/7/164563.pdf
Patel, J. S., Fioranelli, F.  and Anderson, D. (2018) Review of radar classification and RCS characterisation techniques for small UAVs or drones.IET Radar, Sonar and Navigation, 12(9), pp. 911-919. (doi:10.1049/iet-rsn.2018.0020)    This is the author’s final accepted version. There may be differences between this version and the published version. You are advised to consult the publisher’s version if you wish to cite from it. http://eprints.gla.ac.uk/164563/                           Deposited on: 27 June 2018          Enlighten – Research publications by members of the University of Glasgow http://eprints.gla.ac.uk   Review of Radar Classification & RCS Characterisation Techniques for Small UAVs or Drones  Jarez S Patel 1†, Francesco Fioranelli 1, David Anderson 1  1School of Engineering, University of Glasgow, University Avenue, Glasgow, UK †Jarez.Patel@glasgow.ac.uk   Abstract: This review explores radar based techniques currently utilised in literature to monitor small UAVs or drones; several challenges  have  arisen  due  to  their  rapid  emergence  and  commercialisation  within  the  mass  market. The  potential  security threats posed by these systems are collectively presented and the legal issues surrounding their successful integration is briefly outlined. Key difficulties involved in the identification and hence tracking of these ‘radar elusive’ systems are discussed, along with  how  research  efforts  relating  to  drone  detection,  classification  and  RCS  characterisation  are  being  directed  in  order  to address this emerging challenge. Such methods are thoroughly analysed and critiqued; finally, an overall picture of the field in its current state is painted, alongside scope for future work over a broad spectrum. 1.  of this value [13] and predicted to be worth $5.6 billion Introduction Micro  Drones  and  UAVs  have  only  recently  been approved for integration in Low Altitude Airspace (LAA) by the Federal Aviation Administration (FAA) as of Nov. 2013 [1]. As a result of this, the number of registered drones have grown significantly throughout the years, with over 670,000 now  registered  in  the  US  over  2016  [2]. According  to  the FAA  annual  forecast,  they  now  project  a  total  of  up  to  7  million  registered  drones  in  LAA  by  the  year  2020  [3]. However,  many  other  countries  have  yet  to  roll  out  such stringent laws and registration services governing the use of drones,  with  developed  countries  being  the  only  exception [4]. A further issue to the large number of drones, is the lack of active enforcement personnel to police these laws, along with  operational  detection  systems. Commonly  leaving  the police  ill-equipped  for  dealing  with  such  threats  and emergencies  [5]. The  potential  to  misuse  these  widely available,  easy  to  use  and  affordable  platforms  for  serious crime  is  tremendous;  to  list  a  few  examples:  privacy violation, illegal reconnaissance of restricted areas, collision hazards, trafficking of illegal substances and deployment of explosive  weapons  or  chemical  agents  [6]-[9]. Collision dangers  involving  aircraft  and  drones  are  one  of  the  most commonly recurring events, where the authors in [10] proved by calculation that a 2 kg drone retains the equivalent kinetic energy of a 20 mm anti-aircraft shell (nearly twice as large as a .50 calibre), if it struck an aircraft flying at typical cruising velocity. We  have been extremely  fortunate  that  there  have been no terrorist attacks or loss of life to this date involving these commercially available drones. On  the  other  hand,  UAVs  have  found  many  positive applications  in  modern  society,  such  as:  remote  inspection, agriculture,  search  and  rescue,  photography  and  package delivery. These  systems  particularly  favour  environments which  are  physically  demanding  for  human  work, costly  to operate  within,  or  consist  of  a  large  functioning  volume. With the deployment of such systems, typical efficiency, cost effectiveness  and  overall  range  can  be  far  surpassed  [11]. The total value of the drone market is projected to be $127 billion [12], with the agricultural market contributing to 80%  by 2022 [14]. long range Radar systems  can  provide sensing capabilities  in  all-weather  and  light  conditions,  along  with the possibility of quantifying range and velocity concurrently. However, UAVs exhibit characteristics which are difficult to detect  by  typical  air  surveillance  radar,  such  as  low:  RCS, velocity and altitude [15]. Tracking systems incorporated in such radars may actively reject targets of similar properties to that  of  birds,  as tracking performance  [16]. These  technicalities  have  called  for  the opening of a unique area in the market, where new systems are  being  developed  to  actively  detect,  identify  and  track such  targets  [17][18][19]. However,  these  systems  rely  on optical sensors to achieve classification; this is undesirable as adverse  weather  conditions  could  easily  cause  principal responsibilities of the system to fail. this  could  easily  degrade Research in both the characterisation and classification of UAVs and drones have increased drastically; with more than 40 publications emerging in 2017 and many  more recently; whereas in prior years fewer than 10 had been published each year. The  principal  aim  of  such  research  is  to  develop  an understanding of the radar signatures produced in the micro-Doppler domain and to also characterise the RCS perceived. This  would  ultimately  allow  it  to  be  applied  to  real  radars, where appropriate thresholds would be set, detection ranges determined  and  suitable  parameters  devised. There  is  also significant interest in the use of passive radars to detect and distinguish drones, as this does not require the deployment of expensive transmitting hardware, due to the ability to exploit illuminators of opportunity. in The rest of this paper is organised as follows: Section 2 investigates  research  efforts the  context  of  RCS characterisation,  Section  3  is  split  into  subsections  and discusses drone  detection  and  classification  techniques, real implementations of classifiers, neural networks and analyses of micro-motions, Section 4 explores applications of passive radar,  finally,  Section 5  concludes  the  literature  review  and presents areas for future work across the field. 1 2. RCS Characterisation of Drones There  have  been  numerous  papers  which  examine  the RCS characteristics of various drones; many authors present their  results  in  either  received  power  or  RCS  magnitude. However, a common feature with the papers deliberated, is the difference in amplitude from the main body of the drone to the rotor blades. Since this is a relative measurement and all the examined plots in this literature are functions of RCS in  some  way  or  form,  this  feature  will  be  termed  ‘relative amplitude’  throughout  this  section  and  will  be  a  means  of drawing a common variable between the papers discussed. this through  simulation  and  compared The authors in [20] analysed the properties of the popular DJI  Phantom  2,  by  means  of  utilising  a  hybrid  Finite Element Method (FEM) and a Method of Moments (MoM) technique to experimental  results  obtained  at  10  GHz. The  study demonstrates  close  agreement  to  the  principal  reflecting components of the quadcopter and the assumptions made in simulation prove to be justified very well. These being: that the  engine,  battery  and  cable  harnesses  are  assumed  to  be pure  solid  copper  and  the  relative  permittivity  (εr)  of  the ABS in the simulation range from 2.4 to 3.3. Further to this, it  is  then  proven  εr  values  do  not  dramatically  affect  the simulation results. They have also shown that if the target is rotated  about  the  z  axis,  the  bistatic  RCS  analysis  is significantly  affected  and  the  RCS  estimation  proves  to  be more complex. Nevertheless, RCS figures obtained through experiment indicate values in the region of -20 to -30 dBsm, which is between the RCS of a bird and an insect [21]. The  authors  in  [22]  performed  an  RCS  analysis  of  two very different quadcopters available from the DJI series of drones,  these  being:  F450  Flame  Wheel  (4  rotors)  and  the S1000+  Octocopter  (8  rotors). Tests  were  performed  in  an anechoic chamber as a function of angle and frequency for two  cases  of  front  facing  and  rear  facing  configurations. Both  measurements  exhibit  a  distinct  relative  amplitude  of approximately -20 dB, with a HH RCS of -17 dBsm for the quadcopter  and  VV  RCS  of  -8  dBsm  for  the  octocopter, these  findings correspond  well to the physical reflectors of the  target. In  the  frequency  plots  which  are  swept  over  a  2.4 GHz bandwidth from 5.8 to 8.2 GHz, it is interesting to observe  that  there  are  no  nulls  in  the  VV  polarisation, whereas when compared to the HH, trenches of up to 15 dB are measured. Acoustic measurements were also carried out, however the authors determined that ideal conditions would be required in order for this to be reliable in practice. Khristenko,  et  al. [23],  developed  a  fully  calibrated system to  measure the scattering properties of a Cheerson-CX-20 quadcopter with the rotors either on or off, this was done  at  9  GHz  in  horizontal  polarisation  (H-Pol). The relative  amplitude  was  measured  to  be  -25  dB  when  the propellers  are  not  rotating,  corresponding  to  an  RCS  of  -21 dBsm. When they were rotating, the relative amplitude is -22 dB and the RCS is -16 dBsm. From these results, the authors have shown that rotating elements are at least 20 to 25  dB  weaker  than  the  main  body,  hence  the  detection  of blade signatures is complicated further since the main body RCS is already below typical target magnitudes. Ritchie,  et  al. [24]  undertook  an  examination  into  the dependencies  of  rotor  blades  of  different  materials  on polarisation,  frequency  and  azimuth  angle. The  study quantified  differences  in  the  RCS  of  H  and  V  pols  over  a simulated  9  GHz  bandwidth  and  concluded  that  HH  is  far more  stable  over  the  frequency  range  than  VV  (with  VV components  expected  to  be  40  dB  below  the  HH). With respect  to  the  material  used,  it  was  found  that  aluminium and carbon fibre behave very similarly; between 1 and 2.5 dB for L, S and C Band. Whilst reflections from the plastic blades were on average 10 dB lower (L, S band), however this gap was closed in HH measurements at C Band. The authors in [25] performed a practical analysis on the effect  of  polarisation  dependence  on  micro-Doppler signatures for two drones: the DJI Inspire 1 quadcopter and the  HobbyLord  F820  Hexacopter. This involved  a heterodyne Ku Band FMCW radar, transmitting at 43 dBm over  a  bandwidth  of  150  MHz  [26]. The  results  obtained analyse  all  polarisation  combinations  and  agree  with Ritchie’s  findings,  in  that  horizontal  contributions  of  the rotating blade, produce a more stable return when compared to the vertical at low elevation angles (ϕEL). The  work also determined that a Co-Pol configuration received a stronger return  at  a  ϕEL  of  0˚,  whereas  cross-polarisations  (X-Pol) received a higher return when ϕEL is 90˚. It was also proven that the direction of rotation makes no difference and that an increase  in  the  number  of  blades  has  little  impact  on  the overall  RCS  (subject  to  relative  size);  though,  extracting information regarding the rotation speed of the blade is far more complicated for the hexacopter case. In [6], the authors gathered experimental data from a DJI Phantom and a wide variety of birds ranging from the 1.8 kg hooded vulture to the 280 g barn owl. This was performed with an S Band multistatic radar through six different flight paths,  which the monostatic  node. These  resulted  in  a  multitude  of  unique range time intensity (RTI) and spectrogram plots, providing insight  into  the  physical  features  exhibited  by  both  bird  (Fig. 1) and by drone (Fig. 2). transmitting  beam  of intercept the  Fig. 1. Micro-Doppler signature of Barn Owl moving from A to B (A) Monostatic HH (B) Bistatic HH (C) Monostatic HV,  Courtesy of M. Ritchie, et al. (UCL) [6] 2 Fig. 2. Micro-Doppler signatures of DJI Phantom quadcopter drone moving from A to B (A) Monostatic HH (B) Monostatic HV (C) Bistatic HH, Courtesy of M. Ritchie, et al. (UCL) [6] It  was  discovered  that  the  RCS  of  the  drone  was  in-between  that  of  the  barn  owl  and  the  vulture,  however  the contribution  of  the  wings  of  the  birds  are  far  more significant  than  that  of  the  blades  of  the  drone. Most notably, birds do not produce as great Doppler components and reflections in the resultant spectrogram. If the influence of the wings or rotors are taken away, the resultant profiles would  be  practically  identical  and  since  these  additional components  have  significant  dependencies,  it  demonstrates that classification may be incredibly complicated outside of these ideal scenarios. A  unique  approach  was  made  by  the  authors  in  [27], where  they  undertook  experiments  with  an  ultra-wideband ISAR sensor over a bandwidth of 3 GHz, at two frequency bands:  ~C  and  Ku  Band. The  purpose  was  to  identify specific scattering locations and radar reflective surfaces of two  aesthetically  different  drones,  the  DJI  Phantom  2  and the  Inspire  1,  over  a  wide  range  of  azimuth  angles. The results  show  that  even  the  non-metallic  components  can dominate  the  ISAR  intensity  plot,  where  the  plastic  rotor blades  whether  spinning  or  not,  have  minimal  impact. The ISAR images for two different drones at two azimuth angles are  shown  in  Fig. 3,  it  is  interesting  to  observe  the  well-defined components of the drone in the image, immediately revealing  the  principle  reflecting  elements. This  correlates well  with  previously  mentioned  works,  where  it  has  been consistently reported that propellers produce little reflection, whereas the body produces the majority. Guay,  et  al. [28],  undertook  a  different  approach  to analysing  the  RCS  of  a  drone  (Parrot  AR),  by  means  of describing  it  through  a  statistical  model,  due  to  the  great number  of  variables  involved. A  fully  calibrated  RCS measurement  environment  was  setup,  operating  at  8  to  9 GHz  [29]  and  tests  were  carried  out  through  a  range  of angles  and  flight  patterns. The  work  produced  a  statistical description of the drone and then went on to generalise this with  the  radar  equation. RCS  values  obtained  were  in  the region  of  -21  dBsm. It  was  concluded  that  Probability  of Detection (PoD) does not necessarily decrease with increase in  frequency  and  the  drone  in  dynamic  flight  produces  a higher  RCS  than  that  in  static  flight,  due  to  decreased likelihood of scattering from deep nulls. Fig. 3. (a) 3DR Solo, (b) Solo ISAR image at 90° (12–15 GHz), (c) Solo ISAR image at 90° (3–6 GHz), (d) DJI Inspire 1, (e) Inspire 1 ISAR image at 270° (12–15 GHz) (f) Inspire 1 ISAR image at 270° (3–6 GHz)  Courtesy of C. Li, University of Texas (UT) [27] A  summary  of the  RCS  figures  and the  relative amplitudes,  as  gathered  from  the  field  of  drone  RCS characterisation is presented in Table 1. The selected drones from  the  literature  are  similar  in  size  and  are  of  the  quad-propeller  variant,  allowing  comparison  of  the  metrics. The measured RCS of the drone does not show an obvious trend with  frequency,  due  to  the  array  of  materials  and  complex scatterers involved in the experiments. However, the relative amplitude throughout, demonstrating  that  the  discussed  experimentations  have been performed to a high standard. remains  moderately constant Table 1. Summary of RCS values and amplitudes obtained Authors  A. Schroder, et al. [20] A. Herschfelt, et al. [22] A. V. Khristenko, et al [23] M. Ritchie, et al. [24] B. K. Kim, et al. [25] C. Li, et al. [27]  R. Guay, et al. [28]   in literature Frequency / GHz  10.0 5.8 to 8.2 9.0 2.4 14.0 3 to 6 12 to 15 8.5    RCS / dBsm  -20 to -30 -17 -16 N/A N/A -24.2  -14.1 -20.9 Relative Amplitude / dB  -20 -20 -22 -17 -20 N/A  N/A 3 3. Drone Detection & Classification Techniques  There  has  also  been  significant  research  undertaken regarding  the  classification  of  drones,  this  is  widely considered  to  be  the  next  logical  step  after  successfully detecting  the  presence  of  such  a  vehicle. Aveillant  [30], utilised  their  Gamekeeper  16U  phased  array  radar,  which operates at L Band and transmits at 1 KW, it is capable of extended  dwell  times  in  order  to  achieve  fine  Doppler resolution. The  trials  undertaken  involved  a  DJI  Phantom and  a  larger  Aerosky  550  hexacopter  fitted  with  GPS sensors  to  provide  a  ground  truth  during  flight. Data  was also  captured  involving  birds,  as  they  were  within  the surveillance volume during the time of the experiments. The staring capability of the radar allowed the trajectory of the targets  to  be  analysed  and  predicted  using  a  real  time algorithm,  which  updates  at  4  Hz. It  is  proposed  that  this track  information  is  used  as  a  feature  to  aid  in  the discrimination  between  birds  and  drones;  as  it  was  shown that drones exhibit a unique, ‘sharp’ flight pattern which is possible  to  recognise. It  is  also  revealed  that  each  drone produced  a  distinctive  Doppler  plot,  due  to  the  size  of  the drone,  the  rotors  and  the  number  of  them. However,  it  is stated the  classification  capabilities  are  strongly dependent  on  the  stability  of  the  rotors  relative  to  the incident  radar  beam,  hence  a  full  quantitative  analysis  was not performed. that QinetiQ  [31],  explored  the  specific  Doppler  patterns  of various  drones  during  flight,  this  was  done  with  their  X Band  FMCW  radar,  named  Obsidian. A  very  interesting aspect  of  their  analysis  was  the  inclusion  of  a  Doppler spectrum  produced  by  the  DJI  Phantom,  to  which  each contributing component is clarified clearly (Fig. 4). Zone ‘a’ represents the low offset frequencies, caused by the rotation at  the  blade  root;  zones  ‘b’  are  the  mid  offset  frequencies caused  by  the  length  of  the  blade;  and  zone  ‘c’  represents the higher frequencies caused by reflections at the blade tip. The  negative  side  of  the  spectrum  is  when  the  blade  is receding  and  has  a  larger  return  than  when  the  blade  is approaching  [32]. This  could  potentially  be  caused  by  the disparity  in  blade  pitch  as  the  radar  beam  is  scattered differently in the plane of rotation [33]. There are certainly unique features contained in this spectrum, therefore future identification opportunities are very promising. Fig. 4. DJI Phantom 2 Doppler spectrum signature, showing selected bands of interest, Courtesy of S. Harman (Qinetiq) [31]   Advancing  from these  observed  signatures,  further research has been undertaken into how novel features can be extracted  or  even  potentially  generated,  by  means  of investigation into further transformation techniques. Thales, TNO  [15],  proposed  suitable  features  to  be  used  in  a subsequent classification process. These features are: RCS, main velocity component, spectrogram periodicity, spectrum width  (Doppler  bandwidth)  and  spectrogram  symmetry. A feature  which  is  not  typically  analysed  is  the  spectrogram periodicity;  which  extracts  and  quantifies  periodic  micro-Doppler  modulations. This the generation of a cepstrogram, which is the inverse FFT and log  of  the  Doppler-time  spectrum. For  the  extended  dwell times or long integration intervals reported across literature [30][31],  it  would  be  advantageous  to  perform  such  a transform,  as  it  further  quantifies  the  repetitive  nature observed  in  the  spectrogram. In  the  context  of  the  work undertaken, the authors have gathered the spectrograms for a variety  of  small  aerial  vehicles  and  have  generated cepstrograms for each; the result of which show an obvious compression of an otherwise cluttered Doppler spectrum. is  achieved through The  same  authors  [34],  have  also  proposed  further extraction of information through the use of Singular Value Decomposition  (SVD),  a  linear  algebraic  transformation which treats the entire 2D spectrogram as a matrix. This has been  proven  to  produce  extremely  quantitative  features  as observed  in  similar  radar  classification  problems,  such  as human  micro  Doppler,  where  near  perfect  classification between  armed  or  unarmed  individuals  is  reported  [35]. Using  this  approach,  they  have  demonstrated  that  SVD projects valuable time-frequency information into the U and V singular vectors, which classifiers can exploit readily. Ancortek  [36],  undertook  a  detailed  Doppler  analysis using their 24 GHz interferometric radar with dual receiving channels,  over  a  range  of  angles. Spectrograms  were obtained  for  an  increasing  number  of  rotor  configurations, this produced progressively complex spectrograms. Studies undertaken  at  higher  frequencies  are  subject  to  increased atmospheric  effects  and  distortion,  the  latter  could  see benefit  from  an  EMD  oriented  analysis,  allowing  the spectrogram to be broken down prior to classification stages. 3.1. Classification Implementations  A complete classification framework is proposed in [37], to  provide  automatic  and  robust  classification  between  a UAV  and  a  non-UAV  target. The  novel  signal  processing algorithm  developed  is  coined  ‘2D  Complex  Regularised Spectral  Analysis’  and  it  employs  commonly  discarded phase  information  to  produce  a  complex  log  spectrum, which  is  carefully  normalised  to  further  benefit  machine interpretation. Additional  time-frequency  transformations such as the cepstrogram and the Cadence Velocity Diagram (CVD)  are  used  as  sources  of  features  to  complement  the traditional spectrogram, however the authors  have adjusted these  equations  to  exploit  phase  information,  as  it  is  not possible  to  take  the  log  and  absolute  value,  without otherwise  discarding  the  phase. A  Subspace  Reliability Analysis  (SRA)  is  also  undertaken  to  assess  and  discard harmful  features,  detrimental  to  the  classification  process. This is identified through evaluation of the reliability of the class conditional covariance matrices and then removing the 4   un-reliable  feature  dimensions,  in  order  to  maximise  a derived  reward  function. The  authors  apply  their  proposed techniques to data provided by Thales Asia, of a low power X-Band radar monitoring a target scene, where a UAV and various  other  non-UAV  targets  are  operating  within,  it should be noted that these other targets  were  mostly birds. This is also compared to state the art approaches in literature and  is  presented  below  in  (Table. 2). ERR  denotes  Equal Error Rate and FAR denotes False Acceptance Rate, defined at a False Rejection Rate (FRR) of 1%. Table. 2 Comparison between the authors approach and other state of the art methods [37] Method  Dynamic time warping (DTW) [38] Principle Component Analysis (PCA) [39] Spectrogram + PCA CVD + PCA Cepstrogram + PCA Proposed Feature Representation (PFR) + PCA PFR + Subspace Reliability Analysis (SRA) EER / %  8.04 8.19 7.75 6.68 10.17 3.98 3.27 FAR / %  47.42 54.16 27.00 28.41 48.07 4.50 3.89  The results reported demonstrate that their PFR and SRA analysis yields low error rates and has very good false alarm performance,  when  compared the  other  methods implemented  for  this  dataset. A  key  aspect  to  take  away from this work is that it could be undesirable to immediately discard  phase interpreted differently by a machine, when compared to, for example a 2D visual plot which benefits a human operator. information  as it  could  be to There  has  also  been  research  undertaken  involving  the possibility  of  classifying  the  case  of  whether  a  drone  is carrying a payload or not. It is stipulated that the increased mass  causes  a  different  inertial  response  and  subsequently the  rotors  are  exerted  further  to  achieve  the  equivalent manoeuvres [41]. This behaviour is directly observed in the micro-Doppler  spectrum  and  the  potential  combination  of this with a measured track of the drone [40], could perhaps be a viable candidate for reliable payload classification. The authors  in  [41],  utilise  centroid  analysis,  which  determines the  apparent  centre  of  mass  for  the  presented  Doppler spectrum. SVD  was  also  applied  to  the  data  sets  and separate  feature  space  plots  were  generated  for  the  two groups of features. A Naïve Bayes classifier was employed and  very  good  classification  accuracy  was  reported,  with results of at least 96% in the 5 classes of increased mass of the  drone. However,  a  noteworthy  conclusion  from  their analysis  is  that  depending  on  the  classification  task,  i.e. whether the drone is flying or hovering, the performance of the features varied. The SVD approach was more suited to classifying flying drones whereas the centroid analysis was more appropriate for the hovering case. Torvik,  et  al. [42]  studied  how  polarimetry  could  be exploited to aid in the classification between four classes of both  birds  and  drones,  these  are  already  known  to  exhibit very  similar  RCS  characteristics  [43]. The  work  employed  led the  co-polarised  phase  difference,  which up  to  12  extracted  vectors  from  the  radar  signature  across multiple  domains  as  features  for  classification. The  dataset consisted of over 8000 samples and accuracies around 99% were  consistently  reported  using  a  linear  discriminant analysis (LDA) classifier. It was discovered that there were systematic differences in the polarimetric eigenvector value and to improved  classification  rates. It  was  postulated  that  these differences between the two cases were due to a decreased multi-bounce  scattering  effect  and  further  creeping  wave effects  in  the  MIE  resonance  region,  for  the  datasets involving  birds. This  shows  that  there  is  very  useful information to be obtained regarding polarimetry, which can significantly aid in distinguishing between drones and birds. P. Zhang, et al. [44], utilised two CW radars operating at K band and X band, to discriminate between three types of drones (helicopter,  quadcopter  and  hexacopter). The spectrograms  were  decomposed  using  PCA  and  were presented  across  three  dimensions,  an  SVM  algorithm  was then utilised to classify between the types of drones, through enclosing  the  clusters  and  defining  a  suitable  hyperplane. Information from the two radar sensors  was then exploited in order to improve the final decision, leading to an overall accuracy of 97.7% across all three classes. W. Zhang [45], then  proceeded  to  undertake  an  analysis  with  the  same drones  operating  together  in  the  same  target  scene,  in different  combinations  to  see  if  it  was  possible  to  classify the type of drone from the unique CVD signature observed. A K-means clustering method was implemented in order to perform  the  classification  and  overall  accuracies  between the seven scenarios was on average 94.7%. time to  be  analysed  closely  over Given the highly unpredictable nature of drones in flight, techniques  such  as  the  Wavelet  Transform  (WT)  may  find direct applications in this field. The WT enables frequency variations in  a multiresolution  space,  as  opposed  to  an  STFT  where resolution is determined by the depth of the FFT [46]. Other advantages  also  sported,  are:  suitability  for  non-stationary analysis, robust filtering through ability to approximate non-linear  functions  and  also  de-noising  competencies  [47]. WT’s  have  witnessed  successful  applications  in  the  radar detection  of  low  velocity,  small  RCS  targets  amongst complex  sea  environments;  sought  after  for  their  flexible configurability [48]. Rahman, et al. [49] applied WT’s to radar data collected from  a  DJI  Phantom  and  a  bionic  bird,  using  their  phase coherent  W-Band  radar  based  on  a  DDS  architecture. The wavelet  approach  was  chosen  due  to  the  high  Doppler resolution  demands  at  high  frequencies,  offering  lower equivalent computational complexity, when compared to the STFT  (reduction  by  factor  log2n). Tests  were  performed with a single propeller and then all four, at these frequencies it is interesting to see just how much the blade flash pattern changes between the two cases. The scalogram plots of the bionic bird exhibit far more prominent features compared to other  spectrograms lower  frequencies  (<  X  Band),  concluding  that  improved  Doppler  resolution does indeed provide more useful information that will hence benefit potential classification opportunities involving small drones. literature  at in 5 3.2. Neural Network Implementations  There is a still great deal of research to be carried out in order  to  determine  the  most  appropriate  features  and classification methods for every presented scenario. On the other  hand,  there  are  optimised  and  fine-tuned  models readily available to be used for these complex classification tasks. For example, in 2016, the authors [50], exploited the famous  pre-trained  ‘GoogleNet’  Convolutional  Neural Network (CNN) and applied it to spectrograms and CVD’s collected  from  two  flying  drones. The  experiment  utilised the  same bespoke  sensor  and  the  same  drone  models as  in [25][26] and classification between the two types of drone, led to a solid accuracy of 94.7% being achieved. The authors in [51], developed a Multi-Layer Perceptron (MLP) Neural Network (NN) based classifier and parameter estimator which can determine the number of propellers and the  blades  on  a  drone. The  MLP  network  architecture consists of five individual pathways  which accept complex IQ,  time,  frequency  and  also  absolute  data. There  are  two unique  MLP  classifiers  which  first  analyse  the  propeller signatures  and  then  the  number  of  blades,  this  is  then  fed into  an  estimation  algorithm. Classification  accuracy achieved  is  very  dependent  on  SNR  but  is  near  perfect, however  this  has  been  applied  to  synthetic  data. This approach  is  unique  and  it  would  be  very  interesting to  see how it performs on real drone data. to (ACF),  was  employed The  authors  in  [52],  developed  an  S  band  CW  radar featuring  a  90˚  hybrid  IQ  receiver  stage;  this  was  used  to distinguish  between  three  very  different  types  of  micro drone  (AirHog  Firewing  Bird,  Skyrover  helicopter  and  a Radioshack quadcopter). The Spectral Correlation Function (SCF) which is the Fourier transform of the Autocorrelation Function identify  unique modulations  caused  by  the  many  dynamic  components  of the  target  of  interest. A  Deep  Belief  Network  (DBN)  is utilised  as  the  classifier  in  this  work,  unlike  typical  Deep Neural  Networks  (DNNs)  the  layers  are  interconnected rather  than  the  individual  units,  resulting  in  a  very hierarchical and modular design. The data gathered from the trials  is  passed  through  four  SCF  pattern  reference  banks (generated  before  the  trials  and  are  unique  to  each  class), finally these are weighted and summed before being fed into a  classifier  to  make  a  final  decision  on  the  target. Classification accuracies are in the region of 97% between the two models of drone and 99% for the artificial bird. 3.3. Micro-Motion Analyses  In areas which have not yet been copiously applied to the context  of  drone  classification,  significant  mathematical effort  has  been  directed  into  understanding  the  micro-motions of rotating elements [32][53] produced by a broad range of aircraft, beyond the cases of drones or UAVs. The formulations presented in [53] are resilient to the number of blades,  through  utilising  the  Rényi  entropy  of  the  time-frequency  distributions  captured. Such  a  capability  is essential,  as  the  number  of  blades  which  are  observed  on any given drone is highly variable, hence resistance to this technicality is strongly desired. A detailed  method involving  Empirical  Mode Decomposition  (EMD)  to  separate  micro-motions  from  the main  body  for  ISAR  applications  can  be  found  in  [54]. In this  work, a  signal  model  for a rotating element is derived for  an  LFM  chirp,  to  which  a  bespoke  micro  Doppler selection  algorithm  is  designed  around,  this  is  based  on direct  analysis  of  the  intrinsic  mode  function  (IMF). The implementation  of its suitability in decomposing data which is non-stationary and potentially  non-linear  [55];  hence the  suitability  for application in drone classification. is  pursued  for technique this Authors in [56] developed a bespoke homodyne W-Band radar,  assembled  and  attached  at  the  microscopic  level (because  of  losses),  to  automatically  measure  blade  length and  rotation  rate  of  a  drone’s  numerous  rotors. The  DJI phantom  was placed at a distance of 1.5  m away  from the radar and data was recorded for a different number of active propellers. Information was extracted through detecting the envelope of the signatures in the Doppler spectrum, this was possible  as  SNR  was  sufficient reliable thresholding. Blade length could be accurately calculated to within an average error margin of: 0.96%, 2.15% and 1.3% for single, double and quad rotors respectively. to  allow A  brief  summary  of  the  aforementioned  classification methods discussed throughout this entire section, is detailed in Table 3. Important and noteworthy keywords to the works have been signified through bold font. Table 3. Summary of classification techniques used throughout literature  Authors  Purpose  drones at L Band Aveillant [30] Investigate Doppler components produced by QinetiQ [31] Investigate signals produced by drones at X Band Thales, TNO [15] TNO, Thales [34] Ancortek [36] J. Ren, et al [37] M. Ritchie, et al [41] B. Torvik, et al [42] P. Zhang, et al [44] W. Zhang, et al [45] S Rahman, et al [49] B. Kim, et al [50] N. Regev, et al [51] G. Mendis, et al [52] M Adjrad, et al. [53] X. Bai, et al. [54] A. Singh, et al. [56] Explore relevant features and Cepstrograms Explore relevant features and SVD Interferometric analysis at K Band Complex Log spectral analysis including Phase Payload classification with Centroids and SVD Polarimetric feature injection into LDA classifier PCA with SVM classifier CVD analysis with K-Means Clustering Wavelet Decomposition and Analysis ‘GoogleNet’ CNN with merged Doppler Combination of MLP NNs for blade estimation DBN with SCF reference banks Signal component estimation using Rényi Entropy Imaging of micro-motion targets using EMD Determine blade properties with W-Band radar     6 4. Passive Radar Detection  and less covert  operation Research  involving  the  passive  detection  of  drones  have also begun to emerge in parallel with that of active radars. Passive Radars (PR) have a number of advantages over their active radar counterparts, being: lower cost, reduced energy consumption, frequency limitations,  due  to  unrestricted  band  licensing  [57]. Good autocorrelation  properties  are  present inherent transmitted waveform, due to channel specifiers, scrambling codes  and  error  control  measures;  this  minimises  the necessity of waveform design. However, it does come with some disadvantages these being: dependence on transmitters usually a significant distance away and out of the control of the user, reliance on continuous transmission and clear line of  sight  (LoS),  there  are  also  limitations  in  the  maximum detectable range [58]. the in Authors  in  [59],  developed  a  Passive  Bistatic  Radar (PBR) to receive digital television signals at 685 MHz and 738  MHz  simultaneously. Extensive  signal  processing  is applied to filter, compensate and beam form, in this case an Extended  Kalman  Filter  (EKF)  is  employed  to  track  the target  trajectory. A  diagram  of  the  complete  configuration implemented  is  shown  in  Fig. 5,  this  is  akin  to  the subsequently discussed PBR architectures. This arrangement has proved to be very effective in detecting and tracking  a DJI  Phantom  4  across  a large  volume. Interestingly,  a  bird  of  a  comparable  size  to  the  drone, seemed to have entered the search volume and consequently captured  the  track  and  lured  it  away  [60]. This,  having  an identical  effect  to  that  of  a  decoy  target,  in  the  context  of radar  countermeasures  and  radar  warfare  [61]. This  work emphasises  the  importance  of  being  able  to  classify  and reject false targets, to prevent such undesirable effects from occurring. relatively targets  for  detection. Due of  30  MHz. In  the  experimental  trials  a  380  g  Parrot  AR drone and an Amos X4 drone, weighing more than 5 kg is used  as increased availability of GSM stations, up to three Base Transmitting Stations (BTS) can be exploited simultaneously,  forming  a multistatic  radar  scenario;  this  has  been  shown  to  enhance performance,  especially techniques  are realised [63]. if  data  fusion the to Roke  Manor  [64],  used  a  COTS  USRP  to  obtain  3G signals  in  the  UTRA  1  band  (2110  MHz  to  2170  MHz  on the downlink and 1920 MHz to 1980 MHz on the uplink). This yielded a coarse bistatic range resolution of 64 m, but a relatively fine Doppler resolution of 7 Hz / ms-1 adequate for the  detection  of  drone  size  targets. Three  variations  of experiments  were  performed:  mobile  phone  illumination providing  the  reference  signal  on  the  uplink,  micro  base station  providing  a  continuous  downlink  pilot  channel  and finally  base  tower  illumination. Through  these  tests,  very clear  spectrograms  were  generated,  demonstrating the precise  motion  of  both  a  quadcopter  and  a  helicopter  style drone  (Fig. 6). It  is  certainly  interesting  to  see  the  direct benefits of exploiting inadvertent mobile phone illuminators in  the  vicinity  to  enhance  signal  purity. The  calculations explored  by  the  author  reveal  that  the  system  is  indeed limited in detection range, to within an order of 100 meters, due to environmental path loss and also the minimum RCS of  the  target. Although,  detection  of  targets  could  still  be very  well  functional  beyond  this;  however,  classification abilities would be severely hindered at these further ranges. Fig. 6. Micro Base Station Illuminator, Quadcopter Target,  Courtesy of A. Chadwick (Roke Manor Research) [64] Authors in [65], utilised emissions from a Wi-Fi router to detect  and  track  both  a  small  light  aircraft  and  a  very lightweight drone consisting mainly of carbon fibre, through three  spatial  dimensions. Rigorous  signal  processing techniques  were  employed  to  improve  the  quality  and resilience of the received Wi-Fi signal, most notably against interference from other access points (AP). Sidelobe control measures  are  taken  to  mitigate  complex  structures  in  the Ambiguity  Function  (AF)  of  the  reference  signal. An Extensive  Cancellation  Algorithm  (ECA)  is  applied  to suppress  the  direct  breakthrough  and  multipath  effects. Finally,  a  Cell  Average  Constant  False  Alarm  Rate  (CA-7 Fig. 5. Passive Radar Signal Processing Flow Diagram,  Courtesy of X. Wan (Wuhan University) [59]  Fraunhofer [62], utilised their Passive Coherent Location (PCL)  GAMMA-2  radar  system,  which  has  the  ability  to intercept  the  GSM  1800  communications  band  (1.8  GHz), through eight 200 KHz  wide channels,  within a bandwidth  CFAR) is implemented to track the target through the range and velocity planes. The results demonstrate a non-spurious, stable track of the drone through 3D space, however there is no ground truth to verify the accuracy of the passive radar system. abilities  were In [66], the authors derived the Doppler offset induced in an OFDM signal and then took this further to describe how this  could  be  applied  to  a  circular  array  of  transmitters. Typical target velocities are grouped and a CFAR algorithm is designed to enable appropriate detection and track. Initial classification through simulation; however, this was not performed over real target data. The analysis presented in this work can be applied to any  OFDM  transmission  system,  this  is  of  interest  as  5G services are expected to operate between 3 and 4 GHz in the low bands and 24 GHz or more in the high bands [67]. This area of research is open for development and there is scope for  investigation  into  Doppler  signatures  produced  in passive radar systems. demonstrated A  summary  of  important  measures  extracted  from  the aforementioned  literature  is  stated  in  Table  4.  along  with whether  the  work  has  demonstrated  either  detection  and/or classification. Table 4. Summary of passive detection techniques and corresponding frequencies – (‡indicates that there is immediate potential for classification) Authors  Y. Liu, et al [59] Fraunhofer [62] Roke Manor [64] T. Martelli, et al [65] X. Yang, et al [66]   Frequency Range  685 – 738 MHz 1800 MHz Detection /Classification  Detection Detection 2400 – 2500 MHz Detection N/A Detection/Classification‡ 5. Discussion & Conclusion In  this  literature  review,  the  research  efforts  in  the context  of  drone  characterisation  and  classification  using radar  sensors  have  been  thoroughly  reviewed,  including exploration  into  various  nuances  and  techniques  to  each approach. This is an emerging field of research, which takes into account the challenges posed by the potential misuse of these  platforms. The section  deliberates noteworthy elements from each topic and highlights aspects which  could  systematically  advance  the  research  efforts  in the overall field. following 5.1. RCS Characterisation Researchers  in  the  field  of  RCS  examination  have undertaken EM simulations to a high degree of accuracy and have verified acquired results with real experimental data; in all  cases  correlating  well  and  are  justified  appropriately. Bistatic  RCS  estimation  proves  to  be  more  challenging  to predict, due to large dependencies on object alignment and related  angles;  in  addition  to  this,  the  calibration  methods utilised for the monostatic approach were not transferable to  the  bistatic  scenario. A  relative  amplitude  disparity  of approximately -20 dB between the drone body to the blade was  witnessed  across  multiple  papers  where  RCS  was assessed [20]-[25]. The  dependency  on  the  visibility  of  drone  blades  for improved  detection  and  classification  against  non-drone objects or of different models, raises significant issues. The main  being  that  the  large  variability  in  the  materials  and shapes used in the construction of these drones has to also be taken into consideration, this in turn has an effect on the range of RCS values that a radar might expect for a drone. The simple use of a plastic rather than a carbon fibre blade has  already  been  shown  to  have  an  impact  [24],  however there  are  still  many  materials,  sizes,  shapes  and  blade configurations  to  be  explored. With  this  in  mind  and  the scope  of  the  entire  issue,  it  would  not  be  impossible  to imagine  the  emergence  of  drones  exhibiting  true  ‘stealth’ characteristics, in ways more so than they already are. This encourages  further  work  in  improved  detection capabilities through  adaptations  in  perhaps,  radar  parameters  such  as centre frequency, bandwidth and polarisation [68]. Studies  regarding  polarimetry  and  bird  discrimination have concluded that horizontal polarisation is preferable, as it simultaneously observes rotor modulations from the drone and  the  flapping  of  the  bird’s  wings. However,  at  high elevation angles vertical and cross polarisation combinations are  shown  to  provide  improved  SNR. Low  frequency measurements at L Band are established to be not as useful as  S  Band,  nevertheless  classification  performance  is improved  [42][69]. In the  context  of  a  real  drone surveillance  radar,  very  high  elevation  angles  would  be uncommon  as,  drones  typically  operate  at  low  to  medium altitude (below 100 m). the through Research  in  drone  classification  practices  have  largely transfer  of  established been  successful techniques  migrated from  other  Automatic  Target Recognition (ATR) problems. However, the entirety of the mathematics  behind  the  observed  signatures  and  also  the development  of  a  resilient  model  has  not  been  fully investigated; this is due to the incredibly complex dynamics and nature of the target. The main contributing factors being the  number  of  fast  rotating  blades  and  the  wide  range  of angles incident  to the radar, especially during manoeuvres. It  is  therefore  difficult  to  reproduce  the  pure  mathematics behind it, whilst also applying reasonable assumptions to get there. Such an analysis is crucial as it could potentially be a strong factor in drone detection and hence classification, as they will exhibit unique signatures associated to that type or model of drone. This is analogous to Jet Engine Modulation (JEM),  which  is  sometimes  used  to  detect  the  presence  of aircraft from the signatures produced by the jet engines [61]. in  open literature usually assume that the drone is visible to the radar for  sufficient  time  in  order  to  extract  segments  of  micro-Doppler  signatures. This  assumption is  not  always appropriate,  either  for  the  drone  navigating  outside  of  the main  radar  beam,  or  for  the  need  of  steering  the  beam  in other  directions  for  concurrent  radar  tasks. To  address  this issue,  techniques  that  employ  compressive  sensing  and 8 techniques  demonstrated The  classification 2110 -2170 MHz Detection/Classification‡ 5.2. Drone Classification  interpolation  of  ‘punctured’  signatures  [70]  are  of  great interest  due  to  agile  nature  of  the  target. A  noteworthy addition  to  this  is  that:  most  of  the  discussed  work  in classification has been undertaken within ideal scenarios and usually at close range, real operation of a drone introduces a dynamic which is otherwise difficult to reproduce, simulate or  predict,  certainly  having  an  effect  on  classification performance. A further complication to the research, is that the collection of original radar data with drones in operation demands  significant  space,  resources  and  bespoke  radar sensors; the entirety of which is challenging for a university to obtain for research purposes. Substantial  work  has  been  undertaken  regarding  the selection  of  the  most  appropriate  features  through  diverse representations and across many domains. Conversely, great success has been attained through utilising algorithms which intelligently  decompose  datasets,  such  as  CNNs. This alleviates  time  spent  in  fully  understanding  and  extracting the appropriate features, but instead leaving it to the neural network  training  process  to  determine. As  radar  systems become is reasonable  to  assume  that  they  will  be  able  to  fuse  more information  to  enhance  their  classification  capabilities, whilst  also  exploiting  the  latest  developments  from  the artificial intelligence and deep learning community. increasingly  adaptive  and ‘cognitive’, it Multilayer classification procedures are a robust measure for ensuring the validity of a final decision within a network [15][52][63]. This  could  be  employed  over  a  multitude  of domains, such as the cepstrogram, spectrogram, range time or  even  through  track  temporal  evolution  [30][71]. In addition,  during  training  a  bespoke  cost  function  could  be implemented the  overall classification  process  across  multiple  unique  classifiers, potentially indicating locations of performance bottlenecks. to  oversee  and  encapsulate 5.3. Passive Radar Detection of Drones  interest technologies  and is  certainly  a  viable  endeavour  and Passive  radar  in  the  context  of  drone  detection  and classification is becoming  increasingly  attractive  with  the  advancement  of communication in  higher transmission  frequencies. Passive  systems  also  provide capabilities without modifying existing radar transmitters or installing  new  sensors,  benefitting  from  reduced  cost  and spectral  compliance. However,  there  are  certainly  notable drawbacks such as the limited channel bandwidth, leading to poor  range  resolution,  maximum  detectable  range  which  is restricted by the receiver design hence sensitivity and finally the  inability  to  experiment  with  polarisation  combinations. As  a  result  of  these  issues,  classification  between  types  of drones or other targets is far more challenging compared to the equivalent for an active radar, further research needs to be undertaken to investigate this prospect. To  potentially  mitigate  such  disadvantages,  it  could  be favourable to develop and deploy a multistatic radar system, this being a combination of both active and passive sensors, therefore  benefiting  from  techniques  used  in  both  research areas. This would: decrease the reliance on the illuminator, since  the  user  has  direct  control,  waveforms  could  be tailored to suit the mission at hand, the passive nodes could preserve  covert  operation  and  opportunities  for  data  fusion immediately  arise  [72][73]. Given  this,  there  is  scope  to  research  novel  adaptive  and  diverse  waveforms  [74][75], coupled  with  an  intelligent  resource  management  system [76][77]. This  would  allow  optimal  detection  and classification of low RCS targets, through the hardware and also software. Through this complete architecture, there are significant  advantages  to  be  gained  and  potential  too substantial to be ignored. 6. Acknowledgments The  authors  would  like  to  thank  Leonardo  Airborne  & Space  Systems  and  the  EPSRC  for  funding  this  research; and  also:  Matthew  Ritchie,  Chenchen  Li,  Xianrong  Wan, Andrew Chadwick and Stephen Harman, for the kind reuse of their figures for this review. 7. References  [1]  Dorr  L.,  Duquette  A.,  “FAA  Releases  Unmanned  Aircraft  Systems Integration  Roadmap”, [Online]. Available: https://www.faa.gov/news/press_releases/news_story.cfm?newsId=15334, Accessed: Nov. 1 , 2017. 2013. FAA, [2]  Vanian  J.,  “Drone  Registrations  are  Still  Soaring”,  Fortune,  2017. http://fortune.com/2017/01/06/drones-[Online]. registrations-soaring-faa, Accessed: Nov. 2, 2017. Available: 2017. [Online]. [3]  FAA,  “FAA  Aerospace  Forecast  Fiscal  Year  2017  to  2037”,  FAA, Available: https://www.faa.gov/data_research/aviation/aerospace_forecasts/media/FY2017-37_FAA_Aerospace_Forecast.pdf, Accessed. Nov. 2, 2017 “Drone  Laws  by  Country”,  Available: UAV http://www.uavsystemsinternational.com/drone-laws-by-country/, Accessed: Nov. 2, 2017  [4]  UAV  Systems Sys. International, [Online]. 2017. Int. [5]  Yeung  P.,  “Drone  Reports  To  Police  Soar  352%  In  A  Year”, Available: Independent, http://www.independent.co.uk/news/uk/home-news/drones-police-crime-reports-uk-england-safety-surveillance-a7155076.html. Accessed: Nov. 3, 2017. [Online]. 2016. [6]  Ritchie M., Fioranelli F., Griffiths H., & Torvik B., “Monostatic And Bistatic  Radar  Measurements  Of  Birds  And  Micro-Drone,”  in  2016 IEEE Radar Conference, RadarConf 2016, 2016. [7]  Gatteschi  V.,  et  al.,  “New  Frontiers  of  Delivery  Services  Using for Drones:  A  Prototype  System  Exploiting  a  Quadcopter Autonomous  Drug  Shipments,” in  Proceedings  -  International Computer  Software  and  Applications  Conference,  2015,  vol. 2,  pp. 920–927. [8]  BBC,  "Drones  Seized  Over  HMP  Pentonville  Carrying  Drugs  And Phones", Available: http://www.bbc.co.uk/news/uk-england-london-37152665. Accessed: Nov. 4, 2017. [Online]. London, 2016. BBC [9]  BBC, "Dubai Airport Grounds Flights Due To ‘Drone Activity’," in [Online]. Available: BBC  Middle  East,  BBC  News,2016. http://www.bbc.co.uk/news/world-middle-east-37493404. Accessed: Nov. 4, 2017. [10]  Moses  A.,  Rutherford  M.  J.,  and  Valavanis  K.  P.,  “Radar-Based Detection  And  Identification  For  Miniature  Air  Vehicles,”  in Proceedings  of  the  IEEE  International  Conference  on  Control Applications, 2011, pp. 933–940. [11]  Raffaelle  D  A.,  “Can  Drones  Deliver?,”  IEEE  Trans. Autom. Sci. Eng., vol. 11, no. 3, pp. 647–648, 2014. [12]  PWC,  “Global  Report  On  The  Commercial  Applications  Of  Drone Available: Accessed: Technology”, https://www.pwc.pl/pl/pdf/clarity-from-above-pwc.pdf, Nov.25, 2017. [Online]. 2016. [13]  French  S.,  “How  Drones  Will  Drastically  Transform  U.S. Available: Agriculture”, https://www.marketwatch.com/story/how-drones-will-drastically-transform-us-agriculture-in-one-chart-2015-11-17, Accessed: Nov. 25 2017. [Online]. 2015. [14]  Rohan  ,“Agricultural  Drones  Forecast”,  Markets  &  Markets,  2015. Available: [Online]. 9 https://www.marketsandmarkets.com/PressReleases/agriculture-drones.asp, Accessed: Nov. 25, 2017 [15]  Harmanny R. I. A., de Wit J. J. M., and Cabic G. P., ‘Radar Micro-Doppler  Feature  Extraction  Using  The  Spectrogram  And  The Cepstrogram’, 2014 11th European Radar Conference (EuRAD), pp. 165-168, Oct. 2014, Rome, Italy. [16]  Van Keuk, G. and Blackman S. S., “On Phased-Array Radar Tracking And  Parameter  Control,”  IEEE  Trans. Aerosp. Electron. Syst.,  vol. 29, no. 1, pp. 186–194, 1993. [17]  Blighter,  “Anti-UAV  Defence  System”,  Blighter,  2015. [Online]. Available:  http://www.blighter.com/products/auds-anti-uav-defence-system.html, Accessed: Nov. 5, 2017 [18]  Kelvin Hughes, “UAV Drone Detection Radar”, [Online] Available: https://www.kelvinhughes.com/security/uav-drone-detection ,Accessed: Nov 25. 2017. [19]  Advanced  Radar  Technologies  (ART),  “ART  Drone  Sentinel”, Available: [Online] http://www.advancedradartechnologies.com/products-services/art-drone-sentinel ,Accessed: Nov 25. 2017. [20]  Schroder  A.,  et  al.,  “Numerical  And  Experimental  Radar  Cross Section  Analysis  Of  The  Quadrocopter  DJI  Phantom  2”,  in  2015 IEEE Radar Conference - Proceedings, 2015, pp. 463–468. [21]  Pike J., “Radar Cross Section”, Global Security Org, 2011. [Online] https://www.globalsecurity.org/military/world/stealth-Available: aircraft-rcs.htm, Accessed: Nov 7, 2017  [22]  Herschfelt  A.,  et  al.,  “Consumer-Grade  Drone  Radar  Cross-Section IEEE  Radar And  Micro-Doppler  Phenomenology,” Conference, RadarConf 2017, 2017, pp. 0981–0985. in  2017 [23]  Khristenko  A.  V.,  Konovalenko  M.O., Rovkin M.E.,  Khlusov  V.A., Marchenko  A.V.,  Sutulin  A.A.,  Malyutin  N.D.,  ‘A  System  for Measurement  of  Electromagnetic  Wave  Scattered  by  Small  UAVs’, International  Siberian  Conference  on  Control  and  Communications (SIBCON). [24]  Ritchie  M.,  Fioranelli  F.,  Griffiths  H.,  and  Torvik  B.,  ‘Micro-drone RCS  Analysis’,  Presented  at  the  2015  IEEE  Radar  Conference, October 2015, Johannesburg, South Africa. [25]  Kim  B.  K.,  Kang  H.-S.,  and  Park  S.-O.,  “Experimental  Analysis  of Small Drone Polarimetry Based on Micro-Doppler Signature,” IEEE Geosci. Remote Sens. Lett., pp. 1–5, 2017. [26]  Suh, J. S., Minz, L., Jung, D. H., Kang, H. S., Ham, J. W., & Park, S. O. (2017). Drone-Based External Calibration of a Fully Synchronized Ku-Band  Heterodyne  FMCW  Radar. IEEE  Transactions  on Instrumentation and Measurement, 66(8), 2189–2197. [27]  Li, C. J. and Ling H., “An Investigation on the Radar Signatures of Small Consumer Drones,”  IEEE Antennas Wirel. Propag. Lett., vol. 16, pp. 649–652, 2017. [28]  Guay,  R.,  Drolet,  G.,  &  Bray,  J.  R.  (2017). Measurement  and modelling of the dynamic radar cross-section of an unmanned aerial vehicle. IET Radar, Sonar & Navigation, 11(7), 1155–1160. [29]  Guay, R.: ‘The Dynamic Measurement Of Unmanned Aerial Vehicle Radar  Cross  Section’. Master's  thesis,  Royal  Military  College  of Canada, 2016 [30]  Jahangir M., Baker C. J., and Oswald G. A., “Doppler characteristics of micro-drones with L-Band multibeam staring radar,” in 2017 IEEE Radar Conference, RadarConf 2017, 2017, pp. 1052–1057. [31]  Harman  S.,  “Analysis  Of  The  Radar  Return  Of  Micro-Uavs  In Flight,” in 2017 IEEE Radar Conference, RadarConf, 2017, pp. 1159–1164. [32]  Martin  B.,  and  Mulgrew  J.,  “Analysis  Of  The  Theoretical  Radar Return  Signal  Form  Aircraft  Propeller  Blades,”  Radar  Conf. 1990., Rec. IEEE 1990 Int., vol. 0, no. 5, pp. 569–572, 1990. [33]  Martin B., Mulgrew J., “Analysis Of The Effects Of Blade Pitch On The  Radar  Return  Signal  From  Rotating  Aircraft  Blades,”  in  Radar 92. International Conference, 1992, pp. 446–449 [34]  de Wit, J. J. M., Harmanny, R. I. A. and Molchanov P., "Radar micro-Doppler feature extraction using the Singular Value Decomposition," 2014 International Radar Conference, Lille, 2014, pp. 1-6. [35]  Fioranelli F., Ritchie M., and Griffiths H., “Performance analysis of centroid and SVD features for personnel recognition using multistatic micro-Doppler,” IEEE Geosci. Remote Sens. Lett., vol. 13, no. 5, pp. 725–729, 2016. [36]  Nanzer  J. A.    and  Chen  V.  C.,  “Microwave  Interferometric  And Doppler  Radar  Measurements  Of  A  UAV,”  in  2017  IEEE  Radar Conference, RadarConf 2017, 2017, pp. 1628–1633. [37]  Ren  J.,  and  Jiang  X.,  “Regularized  2-D  Complex-Log  Spectral Analysis  And  Subspace  Reliability  Analysis  Of  Micro-Doppler Signature  For  UAV  Detection,”  Pattern  Recognition.,  vol. 69,  pp. 225–237, 2017. [38]  Smith, G. E., Woodbridge K., and Baker, C. J., “Radar Micro-Doppler Signature Classification Using Dynamic Time Warping,” IEEE Trans. Aerosp. Electron. Syst., vol. 46, no. 3, pp. 1078–1096, 2010. [39]  Zabalza, J., Clemente, C., Di Caterina G., Ren J., Soraghan, J. J., and Marshall, S., “Robust PCA Micro-Doppler Classification Using SVM On  Embedded  Systems,”  IEEE  Trans. Aerosp. Electron. Syst.,  vol. 50, no. 3, pp. 2304–2312, 2014. [40]  Mohajerin,  N.,  Histon  J.,  Dizaji,  R.,  and  Waslander,  S.  L.,  “Feature Extraction  And  Radar  Track  Classification  For  Detecting  Uavs  In Civillian Airspace”, in IEEE National Radar Conference Proceedings, 2014, pp. 674–679. [41]  Ritchie  M.,  Fioranelli  F.,  Borrion  H.,  and  Griffiths  H.,  “Multistatic Micro-Doppler  Radar  Feature  Extraction  For  Classification  Of Unloaded/Loaded Micro-Drones,” IET Radar, Sonar Navig., vol. 11, no. 1, pp. 116–124, 2017. [42]  Torvik B., Olsen K. E., and Griffiths H., “Classification of Birds and UAVs  Based  on  Radar  Polarimetry,”  IEEE  Geosci. Remote  Sens. Lett., vol. 13, no. 9, pp. 1305–1309, 2016. [43]  Vaughn  C.  R.,  “Birds  and  Insects  as  Radar  Targets:  A  Review,” Proceedings of the IEEE, vol. 73, no. 2. pp. 205–227, 1985. [44]  Zhang  P.,  Yang  L.,  Chen  G.  and  Li,  G.,  "Classification  of  drones based  on  micro-Doppler  signatures  with  dual-band  radar  sensors," 2017  Progress  in  Electromagnetics  Research  Symposium  -  Fall (PIERS - FALL), Singapore, 2017, pp. 638-643. [45]  Zhang  W.  and  Li,  G.,  "Detection  of  multiple  micro-drones  via cadence velocity diagram analysis," in Electronics Letters, vol. 54, no. 7, pp. 441-443, 4 5 2018. [46]  Mallat, S. G., “A Theory for Multiresolution Signal Decomposition: The  Wavelet  Representation”,  IEEE  Trans. Pattern  Analysis. Mach. Intell., vol. 11, no. 7, pp. 674-693, 1989 [47]  Duk  V.,  Ng  B.,  and  Rosenberg,  L.,  “The  potential  of  2D  wavelet transforms for target detection in sea-clutter,” in IEEE National Radar Conference – Proc., 2015, vol. 2015–June, no. June, pp. 901–906. [48]  Duk V., Rosenberg L., and B. W. H. Ng, “Target Detection in Sea-Clutter Using Stationary Wavelet Transforms,” IEEE Trans. Aerosp. Electron. Syst., vol. 53, no. 3, pp. 1136–1146, 2017. [49]  Rahman, S., & Robertson, D. A. (2017). Time-Frequency Analysis of Millimeter-Wave Radar Micro-Doppler Data from Small UAVs, 1–5. [50]  Kim B. K., Kang H. S., and Park S. O., “Drone Classification Using Convolutional Neural Networks With Merged Doppler Images,” IEEE Geosci. Remote Sens. Lett., vol. 14, no. 1, pp. 38–42, 2017. [51]  Regev,  N.,  Iofedov,  I.  Y.,  and  Wulich,  D.,  “Classification  of  Single and  Multi  Propelled  Miniature  Drones  Using  Multilayer  Perceptron Artificial Neural Network,” pp. 1–5. [52]  Mendis G. J., Randeny T., Wei J. and Madanayake A., "Deep learning based  doppler  radar  for  micro  UAS  detection  and  classification," MILCOM 2016 - 2016  IEEE Military Communications Conference, Baltimore, MD, 2016, pp. 924-929. [53]  Adjrad  M.  and  Woodbridge  K.,  "Imaging  Of  Micromotion  Targets With Unknown Number Of Rotating Parts Based On Time-Frequency Analysis,"  IET  International  Conference  on  Radar  Systems  (Radar 2012), Glasgow, UK, 2012, pp. 1-5. [54]  Bai  X.,  Xing  M.,  Zhou  F.,  Lu  G.,  and  Bao  Z.,  “Imaging  Of Micromotion Targets With Rotating Parts Based On Empirical-Mode Decomposition,” IEEE Trans. Geosci. Remote Sens., vol. 46, no. 11, pp. 3514–3523, 2008. [55]  Gunturkun  U.,  “Bivariate  Empirical  Mode  Decomposition  For Cognitive Radar Scene Analysis,” IEEE Signal Process. Lett., vol. 22, no. 5, pp. 603–607, 2015 [56]  Singh A. K. & Kim Y. H., "Automatic Measurement of Blade Length and  Rotation  Rate  of  Drone  Using  W-Band  Micro-Doppler  Radar," IEEE Sens. Jour., vol. 18, no. 5, pp. 1895-1902, Mar. 1, 1 18. [57]  Griffiths  H.  D.,  “Passive  Bistatic  Radar  and  Waveform  Diversity,” IEEE Conf. Publ., vol. 119, no. c, pp. 189–195, 2010 [58]  Howland,  P.  E.,  Griffiths,  H.  D.  and  Baker,  C.  J. Passive  Bistatic Radar  Systems,  in  Bistatic  Radar:  Emerging  Technology  (ed  M. Cherniakov), John Wiley & Sons, Ltd, Chichester, UK. ch1, 2008. [59]  Liu Y., Wan, X., Tang H., Yi J., Cheng Y., and Zhang X., “Digital Television  Based  Passive  Bistatic  Radar  System  For  Drone Detection,” in 2017 IEEE Radar Conference, 2017, pp. 1493–1497. 10 [60]  Blackman  S.,  Samuel  &  Popoli,  Robert. Design  and  Analysis  of Modern Tracking Systems, 1st Edition, Artech House, 1999 [61]  Stimson,  G.W.,  Griffiths,  H.  D.,  Baker,  C.,  Adamy  D.,  Stimson’s Introduction to Airborne Radar,  3rd Edtion., SciTech, 2014 [62]  Knoedler,  B.,  Zemmari  R.,  and  Koch  W.,  “On  The  Detection  Of Small  UAV  Using  A  GSM  Passive  Coherent  Location  System,”  in Proceedings International Radar Symposium, 2016, vol. 2016–June. [63]  Patel, J. S., Fioranelli, F., Ritchie, M., and Griffiths, H., “Multistatic Radar Classification Of Armed Vs Unarmed Personnel Using Neural Networks,” Evol. Syst., Nov. 2017. [64]  Chadwick,  A.  D.,  “Micro-Drone  Detection  Using  Software-Defined 3G Passive Radar,” pp. 1–6. IET Internation Radar Conference, 2017 [65]  Martelli T., Murgia F., Colone F., Bongioanni, C.,  and Lombardo P., “Detection And 3D Localization Of Ultralight Aircrafts And Drones With A Wifi-Based Passive Radar,” pp. 1–6. [66]  Yang X., Huo K., Jiang W., Zhao J., and Qiu Z., “A Passive Radar System  For  Detecting  UAV  Based  On  The  OFDM  Communication Signal,” in 2016 Progress In Electromagnetics Research Symposium, PIERS 2016 - Proceedings, 2016, pp. 2757–2762. [67]  Barret J., “5G Spectrum Bands”, GSACOM 2017, [Online] Availble: https://gsacom.com/5g-spectrum-bands/ , Accessed: Apr. 19, 2018. [68]  Haykin  S.,  “Cognitive  Radar:  A  Way  Of  The  Future,”  IEEE  Signal Process. Mag., vol. 23, no. 1, pp. 30–40, 2006. [69]  Torvik B., “Investigation Of Non-Cooperative Target Recognition Of Small  And  Slow  Moving  Air  Targets  In  Modern  Air  Defence Surveillance Radar”, Doctoral Thesis, UCL. 2016. [70]  Rossum,  W.  L  van. Anitori  L.,  Dorp  P.  van,  Wit  J.  J.  M.  de  and Harmanny R.  I. A., "Classification of human gaits using interrupted radar  measurements,"  2017  IEEE  Radar  Conf.,  Seattle,  WA,  pp. 0514-0519. [71]  Kozlovskyy  V.,  Parkhomey  I.,  Odarchenko  R.,  Gnatyuk  S.,  and Zhmurko  T.,  “Method  For  UAV  Trajectory  Parameters  Estimation Using  Additional  Radar  Data,”  in  2016  IEEE  4th  International Conference Methods and Systems of Navigation and Motion Control, MSNMC 2016 - Proceedings, 2016, pp. 39–42. [72]  Webster  T.  and  Higgins  T.,  “Detection  Aided  Multistatic  Velocity Backprojection  for  passive  radar,”  in  ICASSP,  IEEE  International Conference  on  Acoustics,  Speech  and  Signal  Processing - Proceedings, 2015, vol. 2015–August, pp. 5580–5584. [73]  Ritchie M., Griffiths H., and Fioranelli F., “Aspect Angle Dependence And  Multistatic  Data  Fusion  For  Micro-Doppler  Classification  Of Armed/Unarmed Personnel,” IET Radar, Sonar Navig., vol. 9, no. 9, pp. 1231–1239, 2015. [74]  Blunt,  S.  D.    and  Mokole  E.  L.,  "Overview  Of  Radar  Waveform Diversity," in IEEE Aerospace and Electronic Systems Magazine, vol. 31, no. 11, pp. 2-42, November 2016. [75]  Jakabosky  J.,  Mccormick  P.,  Blunt  S.  D.,  "Implementation  And Design Of Physical Radar Waveform Diversity," in IEEE Aerospace and Elec. Systems Magazine, vol. 31, no. 12, pp. 26-33, Dec. 2016. [76]  Sherwani  H.,  Griffiths  H.  D.,  "Tracking  Parameter  Control  In Multifunction  Radar  Network  Incorporating  Information  Sharing," 2016  19th Information  Fusion (FUSION), Heidelberg, 2016, pp. 319-326. International  Conference  on [77]  Asnis  G.  and  Blackman  S.,  "Optimal  allocation  of  multi-platform sensor  resources  for  multiple  target  tracking,"14th  International Conference on Information Fusion, Chicago, IL, 2011, pp. 1-8. 11